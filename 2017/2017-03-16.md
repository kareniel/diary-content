**webvr + physical web**

1. beacon broadcast a url
2. users around the beacon connect to the website
3. the web experience is overlaid on top of the field of vision so that digital objects appear in physical space
4. webrtc allows the users to share in real-time their interactions with those digital objects

I'm assuming users are wearing a device that doesn't block their field of vision, such as Snap Spectacles

**spec for using BCI as an input device on the web**

1. bci's stream data to a user's device
2. specific events are mapped to certain types of actions which emit events
3. developers have access to new apis for those listening to those actions
